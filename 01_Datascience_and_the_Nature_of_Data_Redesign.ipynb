{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Datascience and the Nature of Data Redesign"
      ],
      "metadata": {
        "id": "xSCyNKa9bGG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANTICIPATED LESSON TIME:\n"
      ],
      "metadata": {
        "id": "yaFVj052bCs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 hours"
      ],
      "metadata": {
        "id": "I64OMWHdbiAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WHAT YOU WILL LEARN:\n",
        "\n"
      ],
      "metadata": {
        "id": "uqBN-4P0bCva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What is a variable?\n",
        "- What are the different types of variables (nominal, ordinal, interval, and ratio)?\n",
        "- How do I use a library to help with data science?\n",
        "- How can you ensure data integrity and remove duplicate values?"
      ],
      "metadata": {
        "id": "ytEljiaSbgkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEFINITIONS YOU’LL NEED TO KNOW:\n"
      ],
      "metadata": {
        "id": "yqu9bBG4bakM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Variable: measurements of things in the real world.\n",
        "- Nominal: a variable with unordered categories.\n",
        "- Ordinal: a variable with ordered categories.\n",
        "- Interval: a variable that is ordered with evenly spaced\n",
        " measurements.\n",
        "- Ratio: an interval variable with a true zero point.\n",
        "- Datasets: a well-organized set of related information, ready for - study and use, in file form.\n",
        "- Dataframe: a dataset in variable form; like a table made up of rows.\n",
        "- Null value: missing data; null values indicate that there is no value present"
      ],
      "metadata": {
        "id": "_kNhNXhebasw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCENARIO:"
      ],
      "metadata": {
        "id": "npqY6ZiSbavX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fVbWP57fDpA?si=eCoJaF7vp5lQrnC2\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "rZ4cXCKlcMw6",
        "outputId": "c372e55e-d590-478b-fd3d-b67f74bdcd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fVbWP57fDpA?si=eCoJaF7vp5lQrnC2\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ePtRRwLE7lx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## WHAT DO I NEED TO KNOW?:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rwFf24KHbCxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, how can we help Angela and her after-school club? First, let’s consider measurement and how we can record what she needs. We’ll call this ‘data’ to think about all that information.\n",
        "\n",
        "When you hear people talk about \"data,\" you may think that all data is the same. However, there are many different kinds of data. To think through Angelina’s problem, it’s important to understand how to measure things through variables. Different types of variables affect your analysis. If you don't understand these types, you will probably use the wrong analysis!\n",
        "\n",
        "Yikes!\n",
        "\n",
        "So what are the different kinds of data?\n"
      ],
      "metadata": {
        "id": "duB4iQE3dz8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nominal:**\n",
        "\n",
        "A nominal variable is kind of like the ‘name’ of categories.  Nominal variables aren’t ordered like numbers are.\n",
        "\n",
        "An example of this is male or female for biological sex.  We do not say that males come before females or are smaller than females.  They are just different names for the categories.\n"
      ],
      "metadata": {
        "id": "qtMmKxuzdvho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ordinal:**\n",
        "\n",
        "One way to think of ordinal variables is the ‘order’ of something you are measuring.  You can think of it as nominal data but with an ordering from first to last or smallest to largest.  Because of that, the order matters.\n",
        "\n",
        "But here’s the thing, the order might be spaced differently. If it was a race, the distance between a first and second-place finish in a race might be close. But the distance between the second and third-place finish might be really spaced out.\n",
        "\n",
        "As it relates to Angela’s problem, she might look at ordinal variables to see how people rank feelings about air pollution (1.  Strongly disagree…2 Disagree…3…Neither agree/nor disagree…4.  Agree…5 Strongly Disagree).\n"
      ],
      "metadata": {
        "id": "gD9dN1xQdvjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Interval:**\n",
        "\n",
        "Intervals can be a bit wonky. These variables follow an order (like ordinal), but the distance between 1, 2, and so on are all the same. To add another fun twist, 0 does not necessarily mean ‘nothing’.\n",
        "\n",
        "A great example is the temperature in Fahrenheit. 0F doesn’t mean there’s no temperature or no cold or no heat, it’s just a point on the scale that helps us think about how to measure it.\n"
      ],
      "metadata": {
        "id": "-CNc75vGdvl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ratio:**\n",
        "\n",
        "Ratio variables are like interval variables, but the 0 means ‘nothing’. Age and height are good examples because 0 age means you have no age. Also, 0 height means you have no height."
      ],
      "metadata": {
        "id": "LIeA_nHZdvoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOUR TURN:"
      ],
      "metadata": {
        "id": "GnbwKEiqdvqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you understand the building blocks of data science and ideas behind data redesign, it’s time to practice applying these concepts! As you go through this, pay close attention to the different types of variables and how they affect data analysis."
      ],
      "metadata": {
        "id": "G_p805eheSev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 1: Importing the Pandas Library\n",
        "\n",
        "Need extra tools to help solve this problem? Well, we can bring in extra ‘libraries’ to help us do extra data science stuff. You can think of it like an ‘add-on’. In this case, we bring in pandas, which is a popular library for doing data science stuff.  \n"
      ],
      "metadata": {
        "id": "pcTYLu7beT1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly\n"
      ],
      "metadata": {
        "id": "t8kD1DcRecQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Starting the IMPORT:**\n",
        "\n",
        "First, we need to set up a “command” to tell the computer what to do. In this case, “command” is to “import” to bring the add-on package in.\n",
        "\n",
        "Bring in the IMPORT menu, which can be helpful to bring in other data tools. In this case, we're bringing in the import block.\n",
        "\n"
      ],
      "metadata": {
        "id": "baatKKpHej3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Telling what Library to Import:**\n",
        "\n",
        "In the text area, we type the name of the library we want to import. A library is like an extra thing we bring in to give us more coding abilities. In our case, we will type out pandas, which will bring in some cool data manipulation features.\n"
      ],
      "metadata": {
        "id": "fBwwSfEqelNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 3 - Renaming the Library So It’s Easy to Remember:**\n",
        "\n",
        "Once you are done, put the import and package together in a single variable. This handy feature helps cut down on all the typing later on. You can call it whatever is easiest for you to remember. In the example below, we’ve put everything into pd, and we type it in the open area.\n",
        "\n",
        "<details>\n",
        "    <summary>Click to see the blocks...</summary>\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZYmOOpW8AAf7uc?format=png&name=240x240)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "i9KikbaremUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "Bu2XSHlWevMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "O56K9z-oevVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 1 - Starting the IMPORT:**\n",
        "\n",
        "First, we need to set up a “command” to tell the computer what to do. In this case, “command” is to “import” to bring the add-on package in."
      ],
      "metadata": {
        "id": "YZfiPMlTfAyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Telling what Library to Import:**\n",
        "\n",
        "In the text area, we type the name of the library we want to import. A library is like an extra thing we bring in to give us more coding abilities. In our case, we will type out pandas, which will bring in some cool data manipulation features."
      ],
      "metadata": {
        "id": "cH_oEeb0fBF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - Renaming the Library So It’s Easy to Remember:**\n",
        "\n",
        "Once you are done, put the ‘import’ and ‘package’ together in a single variable. This handy feature helps cut down on all the typing later on. Feel free to use whatever name you want that will help you remember it later on. In the example below, we’ve put everything into pd."
      ],
      "metadata": {
        "id": "30L4kegsfBII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 - Run the Code:**\n",
        "\n",
        "Hit ‘control’ and ‘enter’ at the same time to run the data science magic!\n",
        "\n",
        "<details>\n",
        "    <summary>Click to see the code...</summary>\n",
        "    \n",
        "![](https://pbs.twimg.com/media/GZmkVCYWEA4oGso?format=jpg&name=small)\n",
        "\n",
        "</details>\n",
        "\n"
      ],
      "metadata": {
        "id": "c8GCMqpAfBMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Your Turn**: Now it’s your turn! We’re going to dive into the pandas package, which helps us with some really cool data science things. First, let’s import the package and assign it to the variable “pd” to make it easier to use throughout our notebook."
      ],
      "metadata": {
        "id": "_p_OUrngfBXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZxSdi0fOfac5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *Congrats!  Your attempts finally made it!  Now you have successfully imported the \"pandas\" package as the variable \"pd\".*"
      ],
      "metadata": {
        "id": "Ggof8OVefc46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 2: Bringing in the Dataframe\n",
        "\n",
        "Let’s bring in the data that we want to look at."
      ],
      "metadata": {
        "id": "fcIgFc0Pfa2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "bq28FDCwf9y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the variable name you want to use:**\n",
        "\n",
        "Now that we’re all set with our new package to help us to do cool things, let’s bring the data into a variable and call it dataframe. Think of it as a digital spreadsheet with much more power to analyze and manipulate the data!\n",
        "\n",
        "In Blockly, bring in the VARIABLES menu."
      ],
      "metadata": {
        "id": "iGUj3uShf91S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Assign the Dataframe to the Variable You Created:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Rather than type out the full file name for our data, this easy to remember name will hold the data we bring in.\n",
        "\n",
        "In Blockly, go to the Variables and drag the Set block for the dataframe variable. This will allow us to assign the result of a function call to the variable. A function is basically code that does a specific task for us."
      ],
      "metadata": {
        "id": "6LOxWIwVf93X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - Bring in the data:**\n",
        "\n",
        "Now we need to look at the file that has all our data. To load our dataframe, we’ll use a simple command to bring in the file we need (CSV….Comma Separated Values). Let’s say we have a file called ‘VehicleEmissions.csv' in the folder ‘datasets’. We’re telling Python to read the CSV file and store it in a variable called dataframe.\n",
        "\n",
        "From the Variable menu, drag a DO block using the pd variable, go ahead with the do operation read_csv. The read_csv function reads a CSV file and returns a DataFrame object.\n",
        "\n",
        "In our case, let’s bring in the “datasets/VehicleEmissions.csv\" (use the Quotes from the TEXT menu) because that is what Angelina is working with."
      ],
      "metadata": {
        "id": "aJyTn_sQf95w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 - Print the Variable:**\n",
        "\n",
        "Let’s see it now by ‘printing’ and showing our work.\n",
        "\n",
        "Drag the dataframe variable to the workspace, making it available for further use in our program. This step is more of a visualization step, as it allows us to see the variable in the Blockly workspace.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZjdlWqXYA8lxYO?format=png&name=900x900)"
      ],
      "metadata": {
        "id": "Mv3tMRlLf979"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "Bx4j06vFkkW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "QZtlkp8kf9-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the variable name you want to use:**\n",
        "\n",
        "Now that we’re all set with our new package to help us to do cool things, let’s bring the data into a variable called dataframe. Think of it as a digital spreadsheet with much more power to analyze and manipulate the data!"
      ],
      "metadata": {
        "id": "qAygL-_jgezX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Assign the Dataframe to the Variable You Created:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Rather than type out the full file name for our data, this easy to remember name will hold the data we bring in.\n"
      ],
      "metadata": {
        "id": "x4rA5Gp6ge11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - Bring in the data:**\n",
        "\n",
        "Now we need to look at the file that has all our data.\n",
        "\n",
        "To load our dataframe, we’ll use a simple command to bring in the file we need (CSV….Comma Separated Values). Let’s say we have a file called ‘VehicleEmissions.csv' in the folder ‘datasets’. We’re telling Python to read the CSV file and store it in a variable called dataframe. For this function, we need to specify the code as “pd.read_csv”, which makes the code read the csv file. This variable is now our dataframe!\n",
        "\n",
        "In our case, let’s bring in the “datasets/VehicleEmissions.csv\" (user the Quotes from the TEXT menu) because that is what Kiana is working with."
      ],
      "metadata": {
        "id": "TFa9QKiTge4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 - Print the Variable:**\n",
        "\n",
        "Let’s see it now by ‘printing’ and showing our work.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZjdif6W0AYKevK?format=png&name=small)"
      ],
      "metadata": {
        "id": "EUHW7qhjge64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: Now it’s your turn!  Let’s dive in and start working with the data!  We’ll begin by loading it into a dataframe, which will allow us to easily interact with and analyze the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "3U103s94g7DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('datasets/VehicleEmissions.csv')\n",
        "dataframe"
      ],
      "metadata": {
        "id": "BMmk69hug7RV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "3d01f35f-989a-4862-a3b8-b914a517bfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'datasets/VehicleEmissions.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-feeb448a67b3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/VehicleEmissions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/VehicleEmissions.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Explanation**: *Easy-peasy! You have now brought in the dataframe and stored it as a variable that you can reference later on. Now onto the fun part! The dataset contains information about vehicle emissions and various related attributes. Each row represents a different vehicle and provides details such as emissions levels, engine size, fuel consumption, power output, vehicle mass, torque, production year, region, and vehicle type. This dataset is valuable for understanding environmental impacts and can be helpful in studies in science and geography classes.*"
      ],
      "metadata": {
        "id": "4Nr5YW15ge9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 3: Checking the data for missing (null) values\n",
        "\n",
        "Sometimes, you want to spot-check your data before doing more analysis.  One thing that can really mess up analysis is if we have some data that is blank or missing. Missing data can mess up our ability to draw accurate conclusions and mess up our results. So how might Angelina check on that?"
      ],
      "metadata": {
        "id": "RRPi_qShhL6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "cFBSrQm8hMBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Because we want to look at missing data, let’s simply call it missing.\n",
        "\n",
        "On the Variable menu, click Create a variable, and type the name missing to the new variable. On the same menu, drag the Set block of this variable to the workspace. If we see anything is missing, it will say ‘True’. If it’s not missing, it will say ‘False’."
      ],
      "metadata": {
        "id": "1oJebPa-hMEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Look for missing values**  \n",
        "\n",
        "To check if your dataset has missing values (null), you can use Python’s pandas library to explore the data. Specifically, you can use the isnull() function. This method returns a new dataframe of the same shape as the original, but with True in the places where the values are missing and False where they are not.\n",
        "From the Variables menu, drag a DO block for the dataframe object, then select the operation isnull. We are using the isnull function from the dataframe module to check for null values in the dataframe.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZYyCUyXUAA3WdJ?format=png&name=small)\n"
      ],
      "metadata": {
        "id": "b1Qq4v9ehMGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "lhU5e5UKklYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "zQzo3CwuhMIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Because we want to look at missing data, let’s simply call it missing"
      ],
      "metadata": {
        "id": "Zm5OeqnOh58X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Look for missing values**\n",
        "\n",
        "To check if your dataset has missing values, you can use Python’s pandas library to explore the data. Specifically, you can use the isnull() function. This method returns a new dataframe of the same shape as the original, but with True in the places where the values are missing and False where they are not.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZYyEo4bEAA5Toh?format=png&name=360x360)\n"
      ],
      "metadata": {
        "id": "BHVqFWnshMKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: Now it’s your turn! See if you can type in the data that appears above to find if anything is missing that might trip up Angelina and her group. Use the code provided to check your dataset for missing values. Then, decide how you want to handle any missing data that you find.\n"
      ],
      "metadata": {
        "id": "4kslXSoLh_3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing = dataframe.isnull()"
      ],
      "metadata": {
        "id": "Z2mWSaLgiDc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "beb8ec41-c616-4f02-90a3-3c48688c0ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataframe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fa07982d0ee0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *You Got It! Now you’ve checked your dataset for missing values. This helps you to identify any gaps, to decide how you want to handle them to ensure your analysis remains accurate. Are there any other missing values you might have missed?*\n",
        "\n",
        "*The results from the code show that most of the data in the vehicle emissions dataset is complete, with values present in all columns for most rows. However, the last few rows have missing vehicle_type information, indicated by True. This means that while the dataset is mostly complete, a few entries lack this specific detail, which might be necessary for certain analyses or conclusions about vehicle types and their emissions.*"
      ],
      "metadata": {
        "id": "Hl4GwEFBh_5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 4: Counting missing values.\n",
        "\n",
        "We’ve now found our missing values, but how many do we have? To understand how many values are missing in each column, let’s use the .sum() method to count of missing values per column."
      ],
      "metadata": {
        "id": "DnDEabX8iMWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "5dsMOD4piXsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Sum the total of the missing cells:**\n",
        "\n",
        "To count the missing values in each column of the dataframe, we can use the sum() function to add up all the missing cells.\n",
        "\n",
        "From the Variables menu, drag the DO block for the missing variable. With that block, select the sum operation. This function returns the total count of the values in the missing variable, which represents the number of missing values in the dataframe."
      ],
      "metadata": {
        "id": "MDgR40cbiaM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 -  Analyze the results:**\n",
        "\n",
        "The result can now be used for further analysis, such as identifying the extent of missing values, performing data imputation, or reporting the quality of the data.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZY03PtWkAEjc0z?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "b9JKeHexiaRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "NA-pcwpqkmJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "6wZ5wSjsilg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Sum the total of the missing cells:**\n",
        "\n",
        "Count the missing values in each column of the dataframe, we can use the sum() function to add up all the missing cells in the missing variable."
      ],
      "metadata": {
        "id": "5EGiYRzoiljW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 2 - Analyze the results:**\n",
        "\n",
        "The result can now be used for further analysis, such as identifying the extent of missing values, performing data imputation, or reporting the quality of the data.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZY00MKXEAAtLRn?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "GkODCbRPillj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: Let’s give it a go and see what we can do.\n"
      ],
      "metadata": {
        "id": "VGn0kc7RixDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing.sum()"
      ],
      "metadata": {
        "id": "5IIgqAoWi0ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *Well done! You’ve used the missing values  code to count the missing values in each column of your dataset. This helps you identify any columns with missing data that need to be addressed. Let’s find out what’s next.*\n",
        "\n",
        "*The code output reveals that the dataset is mostly complete, with no missing values in most columns. However, there are some missing values in the power_output column (6 missing) and a significant number in the vehicle_type column (385 missing).*"
      ],
      "metadata": {
        "id": "lR5LmP-giln7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 5: Checking the data for duplicate values.\n",
        "\n",
        "One final doublecheck would be to focus on duplicate values. These values can appear when data is entered or collected multiple times by mistake. But why does this matter? If we accidentally count something too much, it could cause us to make the wrong decision. So, how can we identify and remove those duplicates for our practical analysis?"
      ],
      "metadata": {
        "id": "E5HJqWWRhMMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "AYL_mYDHjDAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Because we want to look at missing data, let’s simply call it duplicates so it’s easy for us to remember\n",
        "\n",
        "On the Variable menu, click on Create variable, and type duplicates as the name of the variable. From the same menu, drag the Set block for this variable. This variable will hold a boolean value indicating whether each cell in the dataframe is a duplicate or not."
      ],
      "metadata": {
        "id": "FZI0YosCjDCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Check for duplicated rows**\n",
        "\n",
        "From the Variables menu, drag the DO block for the dataframe variable. With that, select the duplicated function. This function returns a value indicating whether each row in the dataframe is a duplicate or not. If it has duplicate rows, it will say ‘True’.\n"
      ],
      "metadata": {
        "id": "PU5YIRm_jDEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - Calculate the total of duplicates:**\n",
        "\n",
        "In the last step we asked to say ‘True’ everytime there was a duplicate. Now let’s just count them all up.\n",
        "\n",
        "From the Variables menu, drag the duplicates variable. From the Math menu, get a Sum of the list. Lastly, from the Text menu choose a Print block. Connect the sum block with duplicates and that with the print.  "
      ],
      "metadata": {
        "id": "_yMn7eNVjDGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4. Print the variable**\n",
        "\n",
        "The print function will show the result of the sum function on the screen, which will tell us the total count of duplicated rows in the dataframe.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZGpocXUAAg7Yo?format=png&name=small)"
      ],
      "metadata": {
        "id": "q3viHT4SjDIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "bEzBm6GPkqP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "9_a5kaOHjDK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Because we want to look at missing data, let’s simply call it duplicates so it’s easy for us to remember"
      ],
      "metadata": {
        "id": "JETtqzHFjDNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Check for duplicated rows: **\n",
        "\n",
        "Similar to the ways to find extra values, you can use the duplicated() function from Python’s pandas library. This function will return True for any duplicate rows in your dataframe. This code will tell you how many duplicate rows exist in your dataset.\n",
        "duplicates = dataframe.duplicated() print(duplicates.sum())"
      ],
      "metadata": {
        "id": "t770ajBPja22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - Calculate the total of duplicates:**\n",
        "\n",
        "In the last step we asked to say ‘True’ everytime there was a duplicate. Now let’s just count them all up."
      ],
      "metadata": {
        "id": "HaxWA2Adja5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 - Print the variable**\n",
        "\n",
        "The print function will show the result of the sum function on the screen, which will tell us the total count of duplicated rows in the dataframe.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZGse6XsAAs3g-?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "pcdqjNhEja7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: So let’s dive in and see if we can find the ‘extras’ that maybe shouldn’t be there."
      ],
      "metadata": {
        "id": "t_RcZ_FHjugk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = dataframe.duplicated()\n",
        "print(sum(duplicates))"
      ],
      "metadata": {
        "id": "kyNEXxOPjyAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *Nice work! You’ve used the “duplicates” code to check your dataset for any duplicate rows. Identifying and removing these duplicates will help ensure your analysis is accurate and reliable. Did your dataset have any duplicate rows?*\n",
        "\n",
        "*The output shows there are two duplicate rows in the dataset. This means some data entries are repeated, which can affect the accuracy of any analysis. Identifying and possibly removing these duplicates is important to ensure the results reflect the true information about vehicle emissions.*\n"
      ],
      "metadata": {
        "id": "ghXxFYPHja-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 6: Cleaning duplicate values.\n",
        "\n",
        "Now that you’ve done a deep dive, what happens if you want to get rid of them? If the result is anything other than zero, you might need to handle these duplicates."
      ],
      "metadata": {
        "id": "hmQbGywQj2JG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "fOZb24ZVj2LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name. Because we want to look at missing data, let’s simply call it data_cleaned\n",
        "On the Variable menu, click Create variable, then type data_cleaned for the variable's name. On this same menu, drag a Set block for this block. This variable will hold the dataframe after removing duplicates."
      ],
      "metadata": {
        "id": "Kf6iWKrXj2NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 2 - Remove duplicates from the dataframe:**\n",
        "\n",
        "From the Variables menu, drag a DO block for the dataframe variable. With that variable, select the operation drop_duplicates. This function returns a new dataframe with duplicates removed.\n",
        "Step 3 - Print the variable:\n",
        "Let’s print it the variable we just created to see what we get.\n",
        "\n",
        "From the Variables menu, drag the \"data_cleaned\" variable to a new workspace to print the cleaned dataframe for further analysis or visualization.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZIktUXoAANSjY?format=png&name=small)\n"
      ],
      "metadata": {
        "id": "ie5amPjpj2Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "-PRY4DFIkrjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "BaGWklV7j2Rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Write out the name for a variable you want to use:**\n",
        "\n",
        "Just like we did before, let’s type out a variable name.  Because we want to look at missing data, let’s simply call it data_cleaned"
      ],
      "metadata": {
        "id": "kTyiqQJLkLsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Remove duplicates from the dataframe:**\n",
        "\n",
        "If duplicate values are found, you can remove them using the drop_duplicates() function. This will remove all duplicate rows, leaving only unique rows in the dataset.\n",
        "data_cleaned = dataframe.drop_duplicates()\n",
        "Step 3 - Print the variable:\n",
        "Let’s print it the variable we just created to see what we get.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZIinHWQAADvc3?format=png&name=small)"
      ],
      "metadata": {
        "id": "7vKLWNo9j2Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: Now that we’ve found the duplicates and extras, let’s type the code and get rid of them."
      ],
      "metadata": {
        "id": "tm1PdcyjkZE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaned = dataframe.drop_duplicates()\n",
        "data_cleaned"
      ],
      "metadata": {
        "id": "QossnEZ0kabJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *Awesome! You have identified and removed the duplicates using the “data_cleaned” code to clean your dataset. This will help ensure your analysis is based on accurate and unique data*.\n"
      ],
      "metadata": {
        "id": "fzUCu7dJj2WA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal 7: Checking the data to see if it’s clean.\n",
        "\n",
        "Before we tried to see how many duplicates. Let’s double-check to make sure we don’t have any duplicates left over."
      ],
      "metadata": {
        "id": "de5DE-EokesE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Blockly"
      ],
      "metadata": {
        "id": "mui6H3KQket4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Check the total of duplicates:**\n",
        "\n",
        "After removing duplicates, it’s always a good idea to verify that no duplicates remain in the dataset!  Verifying that duplicates were removed\n",
        "\n",
        "From the Variables menu, get a DO block for the data_cleaned variable. With that variable, select the duplicated operation."
      ],
      "metadata": {
        "id": "YmL2rkHpkewD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Count for All Duplicate Rows with ‘Sum’:**\n",
        "\n",
        "\tSo now that we’ve double-checked, let’s sum using the sum() function. If we don’t have any duplicate values, we should get a 0 back.\n",
        "\n",
        "From the Math menu, get a Sum of list block, then connect this with the first block.\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZJ6tEW8AAw_fp?format=png&name=small)"
      ],
      "metadata": {
        "id": "kCyHtLmmkeyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blocks code"
      ],
      "metadata": {
        "id": "xYJdd7cilAqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freehand"
      ],
      "metadata": {
        "id": "Sia5NjiBke0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - Check the total of duplicates:**\n",
        "\n",
        "After removing duplicates, it’s always a good idea to verify that no duplicates remain in the dataset!  Verifying that duplicates were removed\n",
        "`data_cleaned.duplicated() `"
      ],
      "metadata": {
        "id": "cTUhLY5bke2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - Count for All Duplicate Rows with ‘Sum’:**\n",
        "\n",
        "So now that we’ve double-checked, let’s sum using the sum() function. If we don’t have\n",
        "any duplicate values, we should get a 0 back.\n",
        "\n",
        "`data_cleaned.duplicated().sum() `\n",
        "\n",
        "![](https://pbs.twimg.com/media/GZZJ4IZXYAAG-U9?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "PZ4g2JL6lMEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn**: Now it’s your turn! Use the code above to identify any duplicate rows in your dataset. If duplicates exist, remove them and verify that your dataset is clean and ready for analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "TgWVpVxZlMTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data_cleaned.duplicated())"
      ],
      "metadata": {
        "id": "OKRA8x2wllFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: *Just like before, you’ve looked at all the columns and rows looking for any extras in the dataset. As duplicates are removed, you now have a cleaner, more reliable dataset for your analysis. You can now move forward with your analysis, knowing your data is free of duplication.*\n",
        "\n",
        "*The result being 0 indicates that there are no duplicate rows in the data_cleaned dataset. This means all duplicate entries have been successfully removed, ensuring that each row of data is unique and ready for accurate analysis.*"
      ],
      "metadata": {
        "id": "1UiB1WTplldZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WHAT DID YOU LEARN?\n",
        "\n"
      ],
      "metadata": {
        "id": "aH2khzfElz1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lesson, we focused on understanding the basics of variables and their impact on data analysis, which can help solve Angelina’s problem.  We explored different types of variables nominal, ordinal, interval, and ratio, each with unique characteristics that influence how we interpret the data we collect.  Remember Angelina’s after school project, we saw how these concepts apply in practical situations, such as analyzing vehicle emissions and advocating for eco-friendly transportation solutions.\n",
        "\n",
        "To make sure she was on the right track, we imported a library in Python using pandas, we handled any null values using the isnull() function and the .sum() method, and lastly, we detected and handled any remaining outliers using the describe(), boxplot() and others.  Let’s continue learning!\n",
        "\n"
      ],
      "metadata": {
        "id": "vtfAkT02mBNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WHAT’S NEXT?\n"
      ],
      "metadata": {
        "id": "7lA1Q588lz37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Plotting](Plotting)"
      ],
      "metadata": {
        "id": "zWxlJALbmH98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TELL ME MORE:"
      ],
      "metadata": {
        "id": "O9rjsIDFlz6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Art: Data storytelling is an art! Visualize real-world issues like population growth or pollution using charts and graphs from real data on Kaggle.\n",
        "  - Link: Kaggle Datasets\n",
        "- Math: If you are interested in diving deeper into the Math concepts that underlie Data Science, Math is Fun offers additional activities that cover handling data, covering topics such as types of data, methods for displaying data (like graphs and charts), conducting surveys, and understanding probability and statistics.\n",
        "  - Resource: Math is Fun - Data\n",
        "- Computer Science: You can dive deeper into data manipulation and visualization using programming languages like Python.\n",
        "  - Link:  Code.org Data Science\n",
        "- Career Connections: Interested in a career as a data scientist? Explore how skills learned through analyzing and categorizing data could lead to opportunities in data science and beyond.\n",
        "  - Link: Simplilearn: Data Science in 5 Minutes\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KPh27kZIkfDi"
      }
    }
  ]
}